# embedding_client.py
from sentence_transformers import SentenceTransformer
import numpy as np
import torch

# ì „ì—­ ìºì‹± (ì„±ëŠ¥ â†‘)
_model = None

def load_embedding_model():
    global _model
    if _model is None:
        print("ğŸ”µ Loading embedding model: intfloat/e5-small-v2 ...")
        try:
            # CUDA ì‚¬ìš© ê°€ëŠ¥ ì‹œ ìë™ ì‚¬ìš©, ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ CPUë¡œ í´ë°±
            device = "cuda" if torch.cuda.is_available() else "cpu"
            _model = SentenceTransformer(
                "intfloat/e5-small-v2",
                trust_remote_code=True,
                device=device
            )
        except Exception as e:
            # CUDA ì˜¤ë¥˜ ì‹œ CPUë¡œ ê°•ì œ ì „í™˜
            print(f"âš ï¸  CUDA ë¡œë”© ì‹¤íŒ¨, CPUë¡œ ì „í™˜: {e}")
            _model = SentenceTransformer(
                "intfloat/e5-small-v2",
                trust_remote_code=True,
                device="cpu"
            )
    return _model


def embed_query(text: str) -> np.ndarray:
    """
    e5-small-v2 query embedding
    ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ë¥¼ ìƒìœ„ë¡œ ì „ë‹¬ (build_rag_contextì—ì„œ ì²˜ë¦¬)
    """
    try:
        model = load_embedding_model()
        formatted = f"query: {text}"
        return model.encode(
            formatted,
            normalize_embeddings=True
        )
    except RuntimeError as e:
        # CUDA ë©”ëª¨ë¦¬ ì˜¤ë¥˜ ë“± RuntimeError ë°œìƒ ì‹œ CPUë¡œ ì¬ì‹œë„
        if "cuda" in str(e).lower() or "cublas" in str(e).lower():
            print(f"âš ï¸  CUDA ì˜¤ë¥˜ ê°ì§€, CPUë¡œ ì¬ì‹œë„: {e}")
            global _model
            _model = None  # ëª¨ë¸ ì¬ë¡œë”©ì„ ìœ„í•´ ìºì‹œ ì´ˆê¸°í™”
            # CPUë¡œ ê°•ì œ ë¡œë”©
            _model = SentenceTransformer(
                "intfloat/e5-small-v2",
                trust_remote_code=True,
                device="cpu"
            )
            model = _model
            formatted = f"query: {text}"
            return model.encode(
                formatted,
                normalize_embeddings=True
            )
        else:
            # ë‹¤ë¥¸ RuntimeErrorëŠ” ê·¸ëŒ€ë¡œ ì „ë‹¬
            raise


def embed_passage(text: str) -> np.ndarray:
    """
    e5-small-v2 passage embedding
    ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ë¥¼ ìƒìœ„ë¡œ ì „ë‹¬
    """
    try:
        model = load_embedding_model()
        formatted = f"passage: {text}"
        return model.encode(
            formatted,
            normalize_embeddings=True
        )
    except RuntimeError as e:
        # CUDA ë©”ëª¨ë¦¬ ì˜¤ë¥˜ ë“± RuntimeError ë°œìƒ ì‹œ CPUë¡œ ì¬ì‹œë„
        if "cuda" in str(e).lower() or "cublas" in str(e).lower():
            print(f"âš ï¸  CUDA ì˜¤ë¥˜ ê°ì§€, CPUë¡œ ì¬ì‹œë„: {e}")
            global _model
            _model = None  # ëª¨ë¸ ì¬ë¡œë”©ì„ ìœ„í•´ ìºì‹œ ì´ˆê¸°í™”
            # CPUë¡œ ê°•ì œ ë¡œë”©
            _model = SentenceTransformer(
                "intfloat/e5-small-v2",
                trust_remote_code=True,
                device="cpu"
            )
            model = _model
            formatted = f"passage: {text}"
            return model.encode(
                formatted,
                normalize_embeddings=True
            )
        else:
            # ë‹¤ë¥¸ RuntimeErrorëŠ” ê·¸ëŒ€ë¡œ ì „ë‹¬
            raise
