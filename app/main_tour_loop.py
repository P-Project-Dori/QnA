# main_tour_loop.py

import time
import re
from tour_route import TOUR_ROUTE
from stt_service import listen_for_seconds
from tts_service import speak
from llm_client import call_llm
from wakeword_service import is_wakeword, wakeword_label, _levenshtein_distance, _fuzzy_match
from rag_pipeline import build_llm_prompt_for_qa, _truncate_to_two_sentences
from translation_service import translate_question_to_en, translate_answer_from_en, translate, LanguageCode

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ì–¸ì–´ë³„ ê³ ì • ë©˜íŠ¸ & ìŠ¤í¬ë¦½íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PHRASES = {
    "arrived": {
        "ko": "{spot_name}ì— ë„ì°©í–ˆìŠµë‹ˆë‹¤.",
        "en": "We have arrived at {spot_name}.",
    },
    "tour_start_welcome": {
        "ko": "ë„ë¦¬ íˆ¬ì–´ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.",
        "en": "Welcome to the Dori tour.",
    },
    "tour_start_move": {
        "ko": "ê·¸ëŸ¼ ì´ì œ ì²« ë²ˆì§¸ ì¥ì†Œë¡œ ì´ë™í•˜ê² ìŠµë‹ˆë‹¤.",
        "en": "Let's move to the first spot.",
    },
    "tour_end": {
        "ko": "ëª¨ë“  íˆ¬ì–´ê°€ ëë‚¬ìŠµë‹ˆë‹¤. í•¨ê»˜í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!",
        "en": "The tour is finished. Thank you for joining!",
    },
    "qa_intro": {
        "ko": "ì„¤ëª…ì´ ëë‚¬ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”? ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”. ì—†ìœ¼ì‹œë©´ â€˜íŒ¨ìŠ¤â€™ë¼ê³  ë§í•´ì£¼ì…”ë„ ì¢‹ì•„ìš”.",
        "en": "That concludes the explanation. Do you have any questions? If not, you can say 'pass'.",
    },
    "qa_silence": {
        "ko": "ë§ì”€ì´ ì—†ìœ¼ì…”ì„œ ë‹¤ìŒ ì¥ì†Œë¡œ ì´ë™í•˜ê² ìŠµë‹ˆë‹¤.",
        "en": "No response, so we'll move to the next spot.",
    },
    "qa_pass": {
        "ko": "ì•Œê² ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì¥ì†Œë¡œ ì´ë™í• ê²Œìš”.",
        "en": "Okay. We will move to the next spot.",
    },
    "qa_more": {
        "ko": "ì¶”ê°€ë¡œ ê¶ê¸ˆí•˜ì‹  ì  ìˆìœ¼ì‹ ê°€ìš”?",
        "en": "Any other questions?",
    },
    "photo_intro": {
        "ko": "ì´ê³³ì€ ì‚¬ì§„ì´ ì•„ì£¼ ì˜ ë‚˜ì˜¤ëŠ” ì¥ì†Œì˜ˆìš”. ì‚¬ì§„ì„ ì°ì–´ë“œë¦¬ê² ìŠµë‹ˆë‹¤!",
        "en": "This is a great photo spot. I'll take your picture!",
    },
    "photo_positioning": {
        "ko": "ê²½íšŒë£¨ê°€ ì˜ ë³´ì´ëŠ” ìœ„ì¹˜ì— ì„œì£¼ì‹œë©´, ì œê°€ ì ì ˆí•œ ìœ„ì¹˜ë¡œ ì´ë™í•´ì„œ ì‚¬ì§„ì„ ì°ì–´ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ì‚¬ì§„ì„ ì°ì„ ë•ŒëŠ” ì €ë¥¼ ë´ì£¼ì„¸ìš”!",
        "en": "If you stand in a spot with a good view of Gyeong-hoe-ru Pavilion, I'll move to take your picture so you're in the right spot! Please look at me when I take your picture!",
    },
    "photo_countdown": {
        "ko": "5ì´ˆ ë’¤ì— ì‚¬ì§„ì„ ì°ê² ìŠµë‹ˆë‹¤! ì›ƒì–´ì£¼ì„¸ìš”~",
        "en": "I'll take your picture in five seconds! Smile~",
    },
    "photo_shot": {
        "ko": "ì°°ì¹µ!",
        "en": "Click!",
    },
    "photo_saved": {
        "ko": "ì‚¬ì§„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! ë‚˜ì¤‘ì— ë°›ì•„ê°€ì‹¤ ìˆ˜ ìˆì–´ìš”.",
        "en": "Photo saved! You can get it later.",
    },
}


# ê°„ë‹¨í•œ spot ì„¤ëª… ìŠ¤í¬ë¦½íŠ¸ (í•˜ë“œì½”ë”©, ko/enë§Œ)
SPOT_SCRIPTS = {
    "ko": {
        "gwanghwamun": [
            "ê´‘í™”ë¬¸ì€ ê²½ë³µê¶ì˜ ì •ë¬¸ìœ¼ë¡œ, ì¡°ì„  ì™•ì¡°ì˜ ìœ„ì—„ì„ ìƒì§•í•©ë‹ˆë‹¤.",
            "ì„ì§„ì™œë€ê³¼ í•œêµ­ì „ìŸì„ ê±°ì¹˜ë©° ì—¬ëŸ¬ ì°¨ë¡€ í›¼ì†ê³¼ ë³µì›ì„ ë°˜ë³µí–ˆìŠµë‹ˆë‹¤.",
        ],
        "heungnyemun": [
            "í¥ë¡€ë¬¸ì€ ê´‘í™”ë¬¸ì„ ì§€ë‚˜ ê²½ë³µê¶ìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ë‘ ë²ˆì§¸ ë¬¸ì…ë‹ˆë‹¤.",
            "ì™•ì‹¤ ì˜ì‹ì´ ì§„í–‰ë  ë•Œ ì‹ í•˜ë“¤ì´ ëŒ€ê¸°í•˜ë˜ ê³µê°„ê³¼ ë§ë‹¿ì•„ ìˆìŠµë‹ˆë‹¤.",
        ],
        "geunjeongmun": [
            "ê·¼ì •ë¬¸ì€ ê·¼ì •ì „ ì•ë§ˆë‹¹ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ë¬¸ìœ¼ë¡œ, ê³µì‹ ì¡°íšŒì˜ ì…êµ¬ì˜€ìŠµë‹ˆë‹¤.",
        ],
        "geunjeongjeon": [
            "ê·¼ì •ì „ì€ êµ­ì™•ì´ ì •ì‚¬ë¥¼ ë³´ë˜ ì •ì „ìœ¼ë¡œ, ê²½ë³µê¶ì˜ ì¤‘ì‹¬ ê±´ë¬¼ì…ë‹ˆë‹¤.",
            "ì´ê³³ì—ì„œ ì¦‰ìœ„ì‹ê³¼ ì™¸êµ­ ì‚¬ì‹  ì ‘ê²¬ ê°™ì€ êµ­ê°€ ì˜ë¡€ê°€ ì—´ë ¸ìŠµë‹ˆë‹¤.",
        ],
        "sujeongjeon": [
            "ìˆ˜ì •ì „ì€ ì™•ê³¼ ì‹ í•˜ë“¤ì´ í•™ë¬¸ê³¼ ì •ì¹˜ì— ëŒ€í•´ í† ë¡ í•˜ë˜ ì¥ì†Œì˜€ìŠµë‹ˆë‹¤.",
        ],
        "gyeonghoeru": [
            "ê²½íšŒë£¨ëŠ” ì—°ëª» ìœ„ì— ì„¸ì›Œì§„ ëˆ„ê°ìœ¼ë¡œ, ì—°íšŒì™€ ì™¸êµ­ ì‚¬ì‹  ì ‘ëŒ€ë¥¼ ìœ„í•´ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.",
        ],
    },
    "en": {
        "gwanghwamun": [
            "Gwang-wha-mun is the main gate of Gyeong-bok-gung Palace, symbolizing the authority of the Joseon dynasty.",
            "It was damaged and restored multiple times through the Imjin War and the Korean War.",
        ],
        "heungnyemun": [
            "Heung-nye-mun is the second gate after Gwang-wha-mun when entering Gyeong-bok-gung.",
            "It connects to spaces where officials waited during royal ceremonies.",
        ],
        "geunjeongmun": [
            "Geun-jeong-mun is the gate leading to the main courtyard of Geun-jeong-jeon, used for official audiences.",
        ],
        "geunjeongjeon": [
            "Geun-jeong-jeon is the main throne hall where the king handled state affairs.",
            "Coronations and receptions for foreign envoys took place here.",
        ],
        "sujeongjeon": [
            "Su-jeong-jeon was a hall where the king and officials discussed studies and politics.",
        ],
        "gyeonghoeru": [
            "Gyeong-hoe-ru is a pavilion built over a pond, used for banquets and receptions of foreign envoys.",
        ],
    },
}


# ===========================================================
# 1) ìŠ¤íŒŸ ìŠ¤í¬ë¦½íŠ¸ ì½ê¸°
# ===========================================================
def run_spot_intro(spot_code, lang):
    """
    spot_codeì— í•´ë‹¹í•˜ëŠ” ì„¤ëª… ìŠ¤í¬ë¦½íŠ¸ë¥¼ í•˜ë“œì½”ë”©ëœ SPOT_SCRIPTSì—ì„œ ê°€ì ¸ì™€ TTSë¡œ ì½ëŠ”ë‹¤.
    """
    # í•˜ë“œì½”ë”©ëœ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© (ì–¸ì–´ë³„ë¡œ ì§ì ‘ ì œê³µ)
    scripts = SPOT_SCRIPTS.get(lang, {}).get(spot_code) or SPOT_SCRIPTS["en"].get(spot_code, [])
    
    for text in scripts:
        speak(text, lang)
        time.sleep(0.3)
        if _check_wakeword_inline(lang):
            _handle_inline_question(spot_code, lang)
        time.sleep(0.2)


# ===========================================================
# Proper noun normalization for Gyeongbokgung Palace
# ===========================================================
# Palace-related proper nouns with common variations
PALACE_PROPER_NOUNS = {
    "gwanghwamun": ["gwanghwamun", "gwanghwa mun", "gwang hwa mun", "kwanghwamun", "kwanghwa mun"],
    "heungnyemun": ["heungnyemun", "heung nye mun", "heungnye mun", "hungnyemun", "hung nye mun"],
    "geunjeongmun": ["geunjeongmun", "geun jeong mun", "geunjeong mun", "keunjeongmun", "keun jeong mun"],
    "geunjeongjeon": ["geunjeongjeon", "geun jeong jeon", "geunjeong jeon", "keunjeongjeon", "keun jeong jeon"],
    "sujeongjeon": ["sujeongjeon", "su jeong jeon", "sujeong jeon", "sujeongjeon", "su jeong jeon"],
    "gyeonghoeru": ["gyeonghoeru", "gyeong hoe ru", "gyeonghoe ru", "kyeonghoeru", "kyeong hoe ru"],
    "gyeongbokgung": ["gyeongbokgung", "gyeongbok gung", "gyeong bok gung", "kyeongbokgung", "kyeongbok gung"],
}


def _normalize_palace_proper_nouns(text: str, lang: str) -> str:
    """
    Normalize mispronounced palace proper nouns in the question text.
    Uses fuzzy matching to recognize similar pronunciations.
    """
    normalized_text = text
    text_lower = text.lower()
    
    # For each proper noun, check if any variation appears in the text
    for correct_name, variations in PALACE_PROPER_NOUNS.items():
        # Check for exact matches first (most common case)
        for variation in variations:
            if variation in text_lower:
                # Replace with correct name (case-insensitive)
                pattern = re.compile(re.escape(variation), re.IGNORECASE)
                normalized_text = pattern.sub(correct_name, normalized_text)
                if variation != correct_name:
                    print(f"ğŸ” Matched '{variation}' â†’ '{correct_name}'")
                break
        else:
            # If no exact match, try fuzzy matching on words
            words = re.findall(r'\b\w+\b', text_lower)
            for word in words:
                # Check if this word is similar to any variation
                for variation in variations:
                    # Only check words of similar length
                    if abs(len(word) - len(variation)) <= 2 and len(word) >= 4:
                        distance = _levenshtein_distance(word, variation)
                        if distance <= 2:
                            # Replace the word with correct name
                            pattern = re.compile(r'\b' + re.escape(word) + r'\b', re.IGNORECASE)
                            normalized_text = pattern.sub(correct_name, normalized_text)
                            print(f"ğŸ” Fuzzy matched '{word}' â†’ '{correct_name}' (distance: {distance})")
                            break
    
    return normalized_text


# ===========================================================
# 2) ìŠ¤íŒŸ Q&A ì„¸ì…˜
# ===========================================================
def run_qa_session(spot_code, lang):
    """
    ì§ˆë¬¸ â†’ RAG â†’ LLM â†’ TTS
    - ì§ˆë¬¸ì´ ì—†ê±°ë‚˜ 'íŒ¨ìŠ¤' ê³„ì—´ â†’ ìë™ ì´ë™
    - ì§ˆë¬¸ ìˆìœ¼ë©´ ë‹µë³€í•˜ê³  "ì¶”ê°€ ì§ˆë¬¸ ìˆìœ¼ì‹ ê°€ìš”?" ë°˜ë³µ
    
    Note:
    - langì€ wakeword ê°ì§€ ì‹œ ê²°ì •ëœ ì‚¬ìš©ì ì–¸ì–´ë¥¼ ì‚¬ìš©
    - STTëŠ” í•´ë‹¹ ì–¸ì–´ë¡œë§Œ ì¸ì‹ (ìë™ ì–¸ì–´ ê°ì§€ ì—†ìŒ)
    - RAG ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ LLM-only ëª¨ë“œë¡œ ì „í™˜
    """
    # Special intro for geunjeongjeon (covers both geunjeongmun and geunjeongjeon)
    if spot_code == "geunjeongjeon":
        if lang == "ko":
            intro_text = "Geunjeongmunê³¼ Geunjeongjeonì— ëŒ€í•œ ì„¤ëª…ì´ ëë‚¬ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”? ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”. ì—†ìœ¼ì‹œë©´ 'íŒ¨ìŠ¤'ë¼ê³  ë§í•´ì£¼ì…”ë„ ì¢‹ì•„ìš”."
        else:
            intro_text = "That concludes the explanation of Geun-jeong-mun and Geun-jeong-jeon. Do you have any questions? If not, you can say 'pass'."
        speak(intro_text, lang)
    else:
        speak(PHRASES["qa_intro"][lang], lang)

    while True:
        print("ğŸ™ STT ëŒ€ê¸°ì¤‘... (ìµœëŒ€ 10ì´ˆ)")
        user_text = listen_for_seconds(lang=lang, seconds=10)

        # --- 10ì´ˆ ë™ì•ˆ ì•„ë¬´ ë§ ì—†ìœ¼ë©´ ---
        if not user_text:
            speak(PHRASES["qa_silence"][lang], lang)
            return

        normalized = user_text.lower().strip()

        # --- 'íŒ¨ìŠ¤' ê³„ì—´ ë°œí™” ì²˜ë¦¬ ---
        # Use word boundaries to avoid matching "no" in "know" or "not"
        PASS_WORDS = ["íŒ¨ìŠ¤", "ì—†ì–´", "ê´œì°®ì•„", "pass", "no", "ì—†ìŠµë‹ˆë‹¤", "ì•„ë‹ˆì˜¤", "skip", "next"]
        # Check for whole words only (word boundaries)
        words_in_text = set(re.findall(r'\b\w+\b', normalized))
        pass_words_set = set(p.lower() for p in PASS_WORDS)
        if words_in_text.intersection(pass_words_set):
            speak(PHRASES["qa_pass"][lang], lang)
            return

        # --- Proper noun normalization for palace-related terms ---
        normalized = _normalize_palace_proper_nouns(normalized, lang)
        if normalized != user_text.lower().strip():
            print(f"ğŸ“ Normalized question: '{user_text}' â†’ '{normalized}'")

        # ====================================================================
        # Q&A PROCESSING: RAG + LLM
        # ====================================================================
        # This section handles user questions using RAG (Retrieval-Augmented Generation)
        # RAG can be enabled/disabled via ENABLE_RAG flag in config.py
        # 
        # When ENABLE_RAG = True:  Uses knowledge_docs context for accurate answers
        # When ENABLE_RAG = False: Uses LLM general knowledge only
        # ====================================================================
        print(f"ì‚¬ìš©ì ì§ˆë¬¸: {normalized}")

        # ì§ˆë¬¸ì„ ì˜ì–´ë¡œ ë²ˆì—­ (RAGëŠ” ì˜ì–´ë¡œ ì‘ë™)
        question_en = translate_question_to_en(normalized, src=lang)
        print(f"[Q&A] Translated to EN â†’ '{question_en}'")

        # RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        # Note: build_llm_prompt_for_qa() checks ENABLE_RAG flag internally
        # If RAG is disabled, it will generate a prompt without context
        prompt = build_llm_prompt_for_qa(
            spot_code=spot_code,
            user_question=question_en,
            place_id="gyeongbokgung",
            language="en",  # LLMì€ í•­ìƒ ì˜ì–´ë¡œ ë‹µë³€, ì´í›„ ë²ˆì—­
        )
        
        # LLMìœ¼ë¡œ ë‹µë³€ ìƒì„± (ì˜ì–´ë¡œ ë‹µë³€ë°›ìŒ, ì§§ì€ ë‹µë³€ ê°•ì œ)
        answer_en = call_llm(prompt, temperature=0.7, max_tokens=150).strip()
        # ì•ˆì „ì¥ì¹˜: 2ë¬¸ì¥ìœ¼ë¡œ ì œí•œ
        answer_en = _truncate_to_two_sentences(answer_en)
        print(f"[Q&A] LLM answer (EN) â†’ '{answer_en}'")
        
        # ë‹µë³€ì„ ì‚¬ìš©ì ì–¸ì–´ë¡œ ë²ˆì—­
        answer = translate_answer_from_en(answer_en, tgt=lang)
        print(f"[Q&A] Translated answer ({lang}) â†’ '{answer}'")

        speak(answer, lang)
        time.sleep(0.3)

        # --- ì¶”ê°€ ì§ˆë¬¸ ìœ ë„ ---
        speak(PHRASES["qa_more"][lang], lang)


# ===========================================================
# 3) ë§ˆì§€ë§‰ ìŠ¤íŒŸ â€” ì‚¬ì§„ ì´¬ì˜ ëª¨ë“œ
# ===========================================================
def run_photo_mode(lang):
    # Automatically proceed with photo taking after explanation
    speak(PHRASES["photo_intro"][lang], lang)
    time.sleep(0.5)
    
    speak(PHRASES["photo_positioning"][lang], lang)
    time.sleep(1.5)
    
    speak(PHRASES["photo_countdown"][lang], lang)
    # Wait 5 seconds before taking the photo
    time.sleep(5.0)
    
    speak(PHRASES["photo_shot"][lang], lang)
    
    # TODO: ì‹¤ì œ ì¹´ë©”ë¼ ì´¬ì˜ ì½”ë“œ ì—°ê²°
    # capture_photo()
    
    time.sleep(0.5)
    speak(PHRASES["photo_saved"][lang], lang)


# ===========================================================
# 4) ì „ì²´ íˆ¬ì–´ ë£¨í”„
# ===========================================================
def start_dori_tour(lang="ko"):
    """
    ë„ë¦¬ì˜ ì „ì²´ íˆ¬ì–´ ì—”ì§„
    """
    speak(PHRASES["tour_start_welcome"][lang], lang)
    time.sleep(0.3)
    speak(PHRASES["tour_start_move"][lang], lang)
    time.sleep(0.5)

    for spot in TOUR_ROUTE:
        spot_code = spot["spot_code"]
        spot_name = spot.get(f"name_{lang}", spot["name_en"])
        is_photo_spot = spot.get("is_photo_spot", False)

        # ìŠ¤íŒŸ ì´ë¦„ ë©˜íŠ¸
        speak(PHRASES["arrived"][lang].format(spot_name=spot_name), lang)

        # ìŠ¤íŒŸ ì„¤ëª… ì½ê¸°
        run_spot_intro(spot_code, lang)

        # Q&A: geunjeongmunì—ì„œëŠ” ê±´ë„ˆë›°ê³ , geunjeongjeonì—ì„œë§Œ ì‹¤í–‰ (ë‘ ìŠ¤íŒŸ ëª¨ë‘ ì„¤ëª… í›„)
        if spot_code != "geunjeongmun":
            run_qa_session(spot_code, lang)

        # ì‚¬ì§„ ìŠ¤íŒŸì´ë©´ ì‚¬ì§„ ëª¨ë“œ ì‹¤í–‰
        if is_photo_spot:
            run_photo_mode(lang)

    speak(PHRASES["tour_end"][lang], lang)


# ===========================================================
# 5) ì¸ë¼ì¸ ì›¨ì´í¬ì›Œë“œ ì¸í„°ëŸ½íŠ¸ í•¸ë“¤ëŸ¬
# ===========================================================
def _check_wakeword_inline(lang: str) -> bool:
    """
    ì§§ê²Œ STTë¥¼ ëŒë ¤ ì›¨ì´í¬ì›Œë“œê°€ ë“¤ë ¸ëŠ”ì§€ í™•ì¸.
    - 2ì´ˆ ì²­ì·¨, ì„ íƒëœ ì–¸ì–´ ì½”ë“œ ì‚¬ìš©
    """
    text = listen_for_seconds(lang=lang, seconds=2)
    if not text:
        return False
    print(f"[WakeWord-inline] captured: {text}")
    return is_wakeword(text, lang)


def _handle_inline_question(spot_code: str, lang: str):
    """
    ì›¨ì´í¬ì›Œë“œë¡œ ì¸í„°ëŸ½íŠ¸ëœ ê²½ìš° í•œ ë²ˆì˜ ì§ˆë¬¸ì— ë‹µí•˜ê³  ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì´ì–´ê°.
    """
    speak(PHRASES["qa_intro"][lang], lang)

    user_text = listen_for_seconds(lang=lang, seconds=6)
    if not user_text:
        speak(PHRASES["qa_silence"][lang], lang)
        return

    normalized = user_text.lower().strip()
    
    # --- Proper noun normalization for palace-related terms ---
    normalized = _normalize_palace_proper_nouns(normalized, lang)
    if normalized != user_text.lower().strip():
        print(f"ğŸ“ Normalized question: '{user_text}' â†’ '{normalized}'")
    
    print(f"[Q&A-inline] question: {normalized}")

    # ì§ˆë¬¸ì„ ì˜ì–´ë¡œ ë²ˆì—­ (RAGëŠ” ì˜ì–´ë¡œ ì‘ë™)
    question_en = translate_question_to_en(normalized, src=lang)
    
    # RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    # Note: RAG toggle (ENABLE_RAG in config.py) is checked inside build_llm_prompt_for_qa()
    prompt = build_llm_prompt_for_qa(
        spot_code=spot_code,
        user_question=question_en,
        place_id="gyeongbokgung",
        language="en",  # LLMì€ í•­ìƒ ì˜ì–´ë¡œ ë‹µë³€, ì´í›„ ë²ˆì—­
    )
    
    # LLMìœ¼ë¡œ ë‹µë³€ ìƒì„± (ì§§ì€ ë‹µë³€ ê°•ì œ)
    answer_en = call_llm(prompt, temperature=0.7, max_tokens=150).strip()
    # ì•ˆì „ì¥ì¹˜: 2ë¬¸ì¥ìœ¼ë¡œ ì œí•œ
    answer_en = _truncate_to_two_sentences(answer_en)
    
    # ë‹µë³€ì„ ì‚¬ìš©ì ì–¸ì–´ë¡œ ë²ˆì—­
    answer = translate_answer_from_en(answer_en, tgt=lang)
    speak(answer, lang)

    # ì•ˆë‚´ ë©˜íŠ¸ í›„ ìŠ¤í¬ë¦½íŠ¸ë¡œ ë³µê·€
    speak(PHRASES["qa_more"][lang], lang)


# ë³„ì¹­: ê¸°ì¡´ ì½”ë“œ í˜¸í™˜
def run_tour(user_lang="ko", place_id="gyeongbokgung", qa_record_seconds=10.0, max_qa_turns=3):
    """
    Wrapper for legacy import compatibility.
    """
    return start_dori_tour(lang=user_lang)
